test

inference with new dataset
inference speed/accuracy


------------------------------------
data augmentation

#  add other interesting augmentation as such that less keypoints are lost e.g. PerspectiveTransform
# or contrary hide keypoints (using masks of other images) in image data with object to make model more robust

https://github.com/isarandi/synthetic-occlusion (proven in research)

#add a check if joints are outside the image, if so repeat augmentation
# add a filter if there is not enough joints present !!!!!!!!!!

add LSP dataset to LSPET

first train a model on the common joints and than finetune the final layer with the joints that are unique to
certain datasets

#for practical applications and the use of multiple dataset we only use 14 joints
#for now, it can be investigated that richer dataset can be used in such a way that for the
#datasets with less joints it is simply set to invisible

--------------------------------
evaluation

evaluate on random samples from all datasets
--------------------------------
refactor

save and load models

pose2keypoints code

keras to tf.keras


098000546.jpg (561, 1172, 3)
image inres scale fail:  (256, 256) (8, 0, 3)
image inres scale fail:  (256, 256) (14, 0, 3)
image inres scale fail:  (256, 256) (1, 0, 3)
image augm fail:  079118977.jpg (8, 0, 3)
image augm fail:  091545137.jpg (12, 0, 3)
image inres scale fail:  (256, 256) (13, 0, 3)
image augm fail:  043612653.jpg (5, 0, 3)
image inres scale fail:  (256, 256) (6, 0, 3)
image inres scale fail:  (256, 256) (5, 0, 3)
image inres scale fail:  (256, 256) (6, 0, 3)
image inres scale fail:  (256, 256) (4, 0, 3)
image augm fail:  035784116.jpg (5, 0, 3)
image inres scale fail:  (256, 256) (6, 0, 3)
image inres scale fail:  (256, 256) (8, 0, 3)
image inres scale fail:  (256, 256) (3, 0, 3)
image augm fail:  097430374.jpg (4, 0, 3)
image inres scale fail:  (256, 256) (6, 0, 3)
image inres scale fail:  (256, 256) (1, 0, 3)
image inres scale fail:  (256, 256) (4, 0, 3)
image augm fail:  091545137.jpg (12, 0, 3)
image augm fail:  039657856.jpg (6, 0, 3)
image inres scale fail:  (256, 256) (6, 0, 3)
image inres scale fail:  (256, 256) (3, 0, 3)
--------------------
reasearch

reduced architectures: mobilepose (resnet, mobilenetv2)

----------------------

idea

dropout at inference time and average prediction (bayesian)

------------------------
CoreML

rewrite loss to work in 4 dimensions (concat stacks) --> also reduces batch footprint

---------------------------

Models

https://github.com/ashwhall/dsnt/blob/master/DSNT_example.ipynb

downscale model:
reduce num stacks or input/output resolution
use regression model